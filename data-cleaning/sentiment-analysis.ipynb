{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:44:34.582316Z",
     "start_time": "2019-10-23T14:44:32.193283Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from toolbox import ToolBox\n",
    "from textblob import TextBlob\n",
    "\n",
    "# nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:30:03.786520Z",
     "start_time": "2019-10-23T14:30:03.775809Z"
    }
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "sid.polarity_scores('This is not cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:30:04.150584Z",
     "start_time": "2019-10-23T14:30:04.077950Z"
    }
   },
   "outputs": [],
   "source": [
    "tb = ToolBox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:30:06.136277Z",
     "start_time": "2019-10-23T14:30:05.769148Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = tb.load_data_sql(table='user_reviews', where=\"lang = 'en'\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:30:23.792707Z",
     "start_time": "2019-10-23T14:30:23.786067Z"
    }
   },
   "outputs": [],
   "source": [
    "def vader_sentiment_to_df(dataframe):\n",
    "    '''\n",
    "        Gets the sentiment scores of reviews using nltk.sentiment.vader.\n",
    "        \n",
    "        Input: dataframe with reviews\n",
    "        Output: original dataframe + column with sentiment score\n",
    "    '''\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    compound = []\n",
    "    \n",
    "    # iterate over dataframe and calculate sentiment scores per row\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        \n",
    "        scores = list(sid.polarity_scores(row['review']).values())\n",
    "        \n",
    "        comp = scores[3]\n",
    "        \n",
    "        compound.append(comp)\n",
    "    \n",
    "    # turns compound list into a dataframe\n",
    "    compound_df = pd.DataFrame.from_dict({'compound':compound})\n",
    "    \n",
    "    # adds sentiment column to existing dataframe\n",
    "    new_dataframe = pd.concat([dataframe, compound_df], axis = 1)\n",
    "    \n",
    "    # drops unnecessary columsn\n",
    "    new_dataframe = new_dataframe.drop(columns = ['username', 'lang', 'helpful_nb', 'helpful_nb_total'])\n",
    "    \n",
    "    # renames compound column to match database\n",
    "    new_dataframe.rename(columns={'compound':'sentiment'}, inplace=True)\n",
    "    new_dataframe.rename(columns={'index':'id'}, inplace=True)\n",
    "    \n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:36:49.126544Z",
     "start_time": "2019-10-23T14:31:08.042833Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df = vader_sentiment_to_df(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:36:49.143956Z",
     "start_time": "2019-10-23T14:36:49.129693Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:37:24.535049Z",
     "start_time": "2019-10-23T14:37:23.919965Z"
    }
   },
   "outputs": [],
   "source": [
    "# write new_df to pickle file\n",
    "new_df.to_pickle('user_review_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:44:44.327064Z",
     "start_time": "2019-10-23T14:44:44.034705Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load pickle file\n",
    "new_df = pd.read_pickle('user_review_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to load dataframe into the database.....fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:44:45.568224Z",
     "start_time": "2019-10-23T14:44:45.556532Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:44:47.345876Z",
     "start_time": "2019-10-23T14:44:46.241777Z"
    }
   },
   "outputs": [],
   "source": [
    "new_df['date'] = new_df['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:44:50.036710Z",
     "start_time": "2019-10-23T14:44:48.927218Z"
    }
   },
   "outputs": [],
   "source": [
    "data = new_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T14:46:47.107454Z",
     "start_time": "2019-10-23T14:46:10.489878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert rows 100 at a time.\n",
    "with database.atomic():\n",
    "    for idx in range(0, len(data), 1000):\n",
    "        UserReviewsClean.insert_many(data[idx:idx+1000]).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation with Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "from flair.data import Sentence\n",
    "\n",
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = reviews[reviews['grade'] > 90].iloc[12]['review']\n",
    "\n",
    "print(review)\n",
    "\n",
    "s = flair.data.Sentence(review)\n",
    "flair_sentiment.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = flair.models.SequenceTagger.load('nl-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('Eetzaal van de aan het klooster verbonden kweekschool. De meisjes die daar werden opgeleid tot onderwijzeres verbleven intern in een internaat. De enige versieringen in deze zaal bestaan uit religieuze voorstellingen, waaronder een Mariabeeld en een H. Hartbeeld.')\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence with predicted tags\n",
    "# print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"Sint-Janssingel gezien in zuidelijke richting ter hoogte van de Stationsbrug, later Wilhelminabrug. Midden op de achtergrond de molen bij het Wilhelminapark. Rechts de nieuwe bebouwing aan de Kloostersingel, hoek Luybenstraat. De rest van de nieuwe wijk het Zand is nog onbebouwd. Achter de bebouwing is de kerk van de paters Kapucijnen te zien. Links de Sint-Janssingel met daarachter het kloostercomplex van de Marienburg. Fotograaf is Herman de Ruijter HdR\"\n",
    "\n",
    "sentences = [Sentence(sentence) for sentence in raw.split('.')]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    tagger.predict(sentence)\n",
    "    \n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        print(entity)\n",
    "        \n",
    "    print('--------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
